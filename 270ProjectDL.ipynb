{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "270ProjectDL.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eYQlAGA2UHge"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data as Data\n",
        "from torch.autograd import Variable\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = pd.read_csv('./train.csv')\n",
        "testset = pd.read_csv('./test.csv')\n",
        "\n",
        "print(trainset)\n",
        "print(testset)\n",
        "\n",
        "X_train = trainset.iloc[:, 0:20].values\n",
        "Y_train = trainset.iloc[:, 20].values\n",
        "Y_train = Y_train-1\n",
        "\n",
        "X_test = testset.iloc[:, 0:20].values\n",
        "Y_test = testset.iloc[:, 20].values\n",
        "Y_test = Y_test-1\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X_train)\n",
        "X_train = scaler.transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
        "Y_train = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
        "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
        "Y_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UrZaMIUDUfjV",
        "outputId": "d89d8d28-3589-4009-d8a5-b044f2be4b1e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      cache-misses-1  node-loads-1  ...  branch-load-misses-5  label\n",
            "0           36218220       2530196  ...              17816426      7\n",
            "1           34025893       2310966  ...              38927513     23\n",
            "2           36778380       2597194  ...              18699857     17\n",
            "3           35736215       2499164  ...              19137869     12\n",
            "4           33763999       2342137  ...              19270653     24\n",
            "...              ...           ...  ...                   ...    ...\n",
            "1495        32765499       2249790  ...              16673701     26\n",
            "1496        36032964       2675011  ...              16989614      1\n",
            "1497        34176184       2447644  ...              17000473      1\n",
            "1498        32203221       2189984  ...              17285080     26\n",
            "1499        34253061       2361245  ...              17671581     13\n",
            "\n",
            "[1500 rows x 21 columns]\n",
            "     cache-misses-1  node-loads-1  ...  branch-load-misses-5  label\n",
            "0          33534639       2368872  ...              22351242      3\n",
            "1          32232524       2183296  ...              24357368      9\n",
            "2          33022157       2301241  ...              16859615     20\n",
            "3          30530041       2055189  ...              17478380     30\n",
            "4          34681266       2432101  ...              19423388      8\n",
            "..              ...           ...  ...                   ...    ...\n",
            "595        31676766       2147940  ...              18798197      9\n",
            "596        38171975       2742669  ...              17275995     30\n",
            "597        32279778       2202587  ...              17590848     17\n",
            "598        35783099       2524731  ...              19007292      7\n",
            "599        33492002       2357476  ...              34302105     19\n",
            "\n",
            "[600 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_set = Data.TensorDataset(X_train, Y_train)\n",
        "train_loader = Data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "FHiLfQen4Y2i"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(20, 48)\n",
        "        self.fc2 = nn.Linear(48, 96)\n",
        "        self.fc3 = nn.Linear(96, 128)\n",
        "        self.fc4 = nn.Linear(128, 30)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(self.fc4(x))\n",
        "        \n",
        "        return x\n",
        "    \n",
        "model = MLP()"
      ],
      "metadata": {
        "id": "V8n3ZZb2Wuaj"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5000\n",
        "learning_rate = 1e-3\n",
        "batch_no = len(X_train) // batch_size\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "T77hmkveWttv"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    loss_sum = 0\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        y_pred = model(x)\n",
        "        y = y.squeeze()\n",
        "        loss = loss_function(y_pred, y)\n",
        "        loss_sum += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 50 == 0:\n",
        "        print(\"epoch: %d, loss: %f\" % (epoch, loss_sum/batch_size))\n",
        "        acc_sum = 0\n",
        "        acc_sum += (model(X_train).argmax(dim=1) == Y_train.squeeze()).sum()\n",
        "        print(\"train accuracy: %f\" % (acc_sum/len(Y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "futCQSebY5_5",
        "outputId": "853dd0f1-7000-44c9-a3f9-311448d7e6ce"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 50, loss: 0.018197\n",
            "train accuracy: 0.769333\n",
            "epoch: 100, loss: 0.012554\n",
            "train accuracy: 0.836667\n",
            "epoch: 150, loss: 0.009365\n",
            "train accuracy: 0.875333\n",
            "epoch: 200, loss: 0.009047\n",
            "train accuracy: 0.896667\n",
            "epoch: 250, loss: 0.006377\n",
            "train accuracy: 0.900000\n",
            "epoch: 300, loss: 0.005747\n",
            "train accuracy: 0.906000\n",
            "epoch: 350, loss: 0.005206\n",
            "train accuracy: 0.920667\n",
            "epoch: 400, loss: 0.005443\n",
            "train accuracy: 0.924000\n",
            "epoch: 450, loss: 0.004882\n",
            "train accuracy: 0.920667\n",
            "epoch: 500, loss: 0.004187\n",
            "train accuracy: 0.922000\n",
            "epoch: 550, loss: 0.003562\n",
            "train accuracy: 0.926667\n",
            "epoch: 600, loss: 0.003681\n",
            "train accuracy: 0.915333\n",
            "epoch: 650, loss: 0.003873\n",
            "train accuracy: 0.926667\n",
            "epoch: 700, loss: 0.003518\n",
            "train accuracy: 0.924667\n",
            "epoch: 750, loss: 0.003603\n",
            "train accuracy: 0.924000\n",
            "epoch: 800, loss: 0.003110\n",
            "train accuracy: 0.926000\n",
            "epoch: 850, loss: 0.003282\n",
            "train accuracy: 0.918000\n",
            "epoch: 900, loss: 0.002976\n",
            "train accuracy: 0.923333\n",
            "epoch: 950, loss: 0.003073\n",
            "train accuracy: 0.933333\n",
            "epoch: 1000, loss: 0.002913\n",
            "train accuracy: 0.931333\n",
            "epoch: 1050, loss: 0.003092\n",
            "train accuracy: 0.930667\n",
            "epoch: 1100, loss: 0.003170\n",
            "train accuracy: 0.934667\n",
            "epoch: 1150, loss: 0.002832\n",
            "train accuracy: 0.923333\n",
            "epoch: 1200, loss: 0.002866\n",
            "train accuracy: 0.928667\n",
            "epoch: 1250, loss: 0.002911\n",
            "train accuracy: 0.935333\n",
            "epoch: 1300, loss: 0.003285\n",
            "train accuracy: 0.932000\n",
            "epoch: 1350, loss: 0.002940\n",
            "train accuracy: 0.929333\n",
            "epoch: 1400, loss: 0.002900\n",
            "train accuracy: 0.938000\n",
            "epoch: 1450, loss: 0.002933\n",
            "train accuracy: 0.929333\n",
            "epoch: 1500, loss: 0.002894\n",
            "train accuracy: 0.936000\n",
            "epoch: 1550, loss: 0.002756\n",
            "train accuracy: 0.928000\n",
            "epoch: 1600, loss: 0.002909\n",
            "train accuracy: 0.928000\n",
            "epoch: 1650, loss: 0.002846\n",
            "train accuracy: 0.934000\n",
            "epoch: 1700, loss: 0.002836\n",
            "train accuracy: 0.914667\n",
            "epoch: 1750, loss: 0.002848\n",
            "train accuracy: 0.939333\n",
            "epoch: 1800, loss: 0.003053\n",
            "train accuracy: 0.928667\n",
            "epoch: 1850, loss: 0.003074\n",
            "train accuracy: 0.933333\n",
            "epoch: 1900, loss: 0.002975\n",
            "train accuracy: 0.932000\n",
            "epoch: 1950, loss: 0.003436\n",
            "train accuracy: 0.930000\n",
            "epoch: 2000, loss: 0.003256\n",
            "train accuracy: 0.920000\n",
            "epoch: 2050, loss: 0.002811\n",
            "train accuracy: 0.916000\n",
            "epoch: 2100, loss: 0.003021\n",
            "train accuracy: 0.922000\n",
            "epoch: 2150, loss: 0.002929\n",
            "train accuracy: 0.932000\n",
            "epoch: 2200, loss: 0.002877\n",
            "train accuracy: 0.923333\n",
            "epoch: 2250, loss: 0.003262\n",
            "train accuracy: 0.920000\n",
            "epoch: 2300, loss: 0.002902\n",
            "train accuracy: 0.920000\n",
            "epoch: 2350, loss: 0.002857\n",
            "train accuracy: 0.934667\n",
            "epoch: 2400, loss: 0.002883\n",
            "train accuracy: 0.941333\n",
            "epoch: 2450, loss: 0.002798\n",
            "train accuracy: 0.935333\n",
            "epoch: 2500, loss: 0.002945\n",
            "train accuracy: 0.930000\n",
            "epoch: 2550, loss: 0.003143\n",
            "train accuracy: 0.930000\n",
            "epoch: 2600, loss: 0.003455\n",
            "train accuracy: 0.945333\n",
            "epoch: 2650, loss: 0.002787\n",
            "train accuracy: 0.938667\n",
            "epoch: 2700, loss: 0.002823\n",
            "train accuracy: 0.935333\n",
            "epoch: 2750, loss: 0.003178\n",
            "train accuracy: 0.938000\n",
            "epoch: 2800, loss: 0.003327\n",
            "train accuracy: 0.942667\n",
            "epoch: 2850, loss: 0.003269\n",
            "train accuracy: 0.924667\n",
            "epoch: 2900, loss: 0.003040\n",
            "train accuracy: 0.926667\n",
            "epoch: 2950, loss: 0.003349\n",
            "train accuracy: 0.922000\n",
            "epoch: 3000, loss: 0.002853\n",
            "train accuracy: 0.940000\n",
            "epoch: 3050, loss: 0.002734\n",
            "train accuracy: 0.929333\n",
            "epoch: 3100, loss: 0.003129\n",
            "train accuracy: 0.928667\n",
            "epoch: 3150, loss: 0.002891\n",
            "train accuracy: 0.924000\n",
            "epoch: 3200, loss: 0.003125\n",
            "train accuracy: 0.935333\n",
            "epoch: 3250, loss: 0.002751\n",
            "train accuracy: 0.936000\n",
            "epoch: 3300, loss: 0.002519\n",
            "train accuracy: 0.924000\n",
            "epoch: 3350, loss: 0.003152\n",
            "train accuracy: 0.922667\n",
            "epoch: 3400, loss: 0.003316\n",
            "train accuracy: 0.935333\n",
            "epoch: 3450, loss: 0.002884\n",
            "train accuracy: 0.921333\n",
            "epoch: 3500, loss: 0.003942\n",
            "train accuracy: 0.924667\n",
            "epoch: 3550, loss: 0.002834\n",
            "train accuracy: 0.939333\n",
            "epoch: 3600, loss: 0.002780\n",
            "train accuracy: 0.936667\n",
            "epoch: 3650, loss: 0.002631\n",
            "train accuracy: 0.934000\n",
            "epoch: 3700, loss: 0.002924\n",
            "train accuracy: 0.939333\n",
            "epoch: 3750, loss: 0.003257\n",
            "train accuracy: 0.946000\n",
            "epoch: 3800, loss: 0.002986\n",
            "train accuracy: 0.932667\n",
            "epoch: 3850, loss: 0.002421\n",
            "train accuracy: 0.934667\n",
            "epoch: 3900, loss: 0.002550\n",
            "train accuracy: 0.930000\n",
            "epoch: 3950, loss: 0.003108\n",
            "train accuracy: 0.924000\n",
            "epoch: 4000, loss: 0.002499\n",
            "train accuracy: 0.930667\n",
            "epoch: 4050, loss: 0.003550\n",
            "train accuracy: 0.933333\n",
            "epoch: 4100, loss: 0.002903\n",
            "train accuracy: 0.935333\n",
            "epoch: 4150, loss: 0.002570\n",
            "train accuracy: 0.939333\n",
            "epoch: 4200, loss: 0.003173\n",
            "train accuracy: 0.943333\n",
            "epoch: 4250, loss: 0.003396\n",
            "train accuracy: 0.928000\n",
            "epoch: 4300, loss: 0.003123\n",
            "train accuracy: 0.934000\n",
            "epoch: 4350, loss: 0.002918\n",
            "train accuracy: 0.938667\n",
            "epoch: 4400, loss: 0.002621\n",
            "train accuracy: 0.933333\n",
            "epoch: 4450, loss: 0.002661\n",
            "train accuracy: 0.931333\n",
            "epoch: 4500, loss: 0.003361\n",
            "train accuracy: 0.934667\n",
            "epoch: 4550, loss: 0.003533\n",
            "train accuracy: 0.938000\n",
            "epoch: 4600, loss: 0.003013\n",
            "train accuracy: 0.920667\n",
            "epoch: 4650, loss: 0.002807\n",
            "train accuracy: 0.944667\n",
            "epoch: 4700, loss: 0.002709\n",
            "train accuracy: 0.933333\n",
            "epoch: 4750, loss: 0.002866\n",
            "train accuracy: 0.934667\n",
            "epoch: 4800, loss: 0.003076\n",
            "train accuracy: 0.928000\n",
            "epoch: 4850, loss: 0.002949\n",
            "train accuracy: 0.937333\n",
            "epoch: 4900, loss: 0.002864\n",
            "train accuracy: 0.936667\n",
            "epoch: 4950, loss: 0.003455\n",
            "train accuracy: 0.930000\n",
            "epoch: 5000, loss: 0.002861\n",
            "train accuracy: 0.925333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "acc_sum = 0\n",
        "print(model(X_test).argmax(dim=1))\n",
        "print(Y_test.squeeze())\n",
        "acc_sum += (model(X_test).argmax(dim=1) == Y_test.squeeze()).sum()\n",
        "print(\"test accuracy: %f\" % (acc_sum/len(Y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPhwGbpoZRCi",
        "outputId": "eea5337d-7bf7-4318-92e7-54ef217aff4c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  8, 19, 29,  7, 22, 12, 28, 29, 11, 24, 27, 12, 20, 29, 12, 17, 18,\n",
            "         8, 22, 19, 22,  9, 12,  2,  1,  0,  1,  0,  4, 18, 16, 22,  3,  2, 11,\n",
            "        24,  9, 14, 29,  5,  6,  8,  9, 21,  5, 18, 26, 14, 27,  7, 15, 25, 23,\n",
            "         7, 27, 16,  5,  6,  0,  2,  8, 26, 18,  3,  5, 17, 18,  2, 22,  9,  4,\n",
            "        26, 17, 28, 11, 19, 14, 27, 16, 17, 14, 18,  3, 14, 15, 23, 22,  8,  3,\n",
            "        12,  3, 13,  1, 20,  0, 29, 15,  8,  2, 14, 13, 12,  6, 20, 13, 11, 15,\n",
            "         5, 21,  8, 28, 24, 10, 10,  1, 14, 19, 11, 29,  6, 28,  5, 26, 14, 20,\n",
            "        11, 17, 28, 22, 16, 23,  5,  3,  4,  0,  1,  3, 16, 11,  5, 27, 12, 26,\n",
            "        28, 12, 11, 18, 20, 10, 11,  7,  3, 23,  9,  1, 20, 27, 13, 14, 23, 19,\n",
            "        23,  4, 14, 18, 11,  3, 16, 24, 12, 24, 10, 14, 25, 18,  2, 24,  7, 14,\n",
            "        18,  7, 23, 13,  1, 13, 22, 22, 19,  4,  0,  7,  6, 22, 15, 29, 13, 20,\n",
            "        10, 27, 29, 28, 19, 16,  5, 17,  0, 10, 29,  9,  0, 28,  9,  0, 13, 15,\n",
            "        23, 20, 23, 26, 10, 12, 11,  9,  0,  4, 15, 19, 21, 14,  8, 22,  4, 27,\n",
            "        11,  7, 19, 19, 27, 19, 14, 23, 19,  1, 12, 29,  9,  9, 13, 19, 17,  4,\n",
            "        13,  4, 10, 11,  7, 12,  8, 16, 18,  3, 29, 20,  6,  1, 16,  9,  1, 24,\n",
            "         8, 17, 20, 15, 13,  7, 18, 26, 14,  7, 24, 29,  4, 20, 27, 20, 22, 26,\n",
            "        18, 17,  2, 20,  1, 10, 14,  5, 18,  0,  8,  7, 22, 19,  9, 21, 22, 23,\n",
            "        14,  1, 15, 21, 13, 26,  7, 27,  4,  1, 29, 17, 21, 11, 17,  4,  6, 21,\n",
            "        24,  4,  7, 24, 12,  2, 15, 11, 17, 24,  1,  5, 12, 28, 16, 14, 25, 13,\n",
            "        21, 13, 25, 26, 24, 27, 27, 27, 16, 12, 11, 18,  9,  7, 19,  8,  0, 17,\n",
            "        20,  3, 11, 25,  2,  5, 17, 10,  5, 28,  8, 21, 25,  6, 17, 12,  6, 22,\n",
            "        12,  6, 11,  0,  2, 12, 24,  5, 18, 17, 22,  7, 18, 19, 23, 24, 16, 27,\n",
            "         0, 13, 20, 25, 27,  3,  0,  6,  3,  9, 21, 25, 18,  7,  5,  7,  2,  2,\n",
            "        27, 28,  2, 22, 12,  2,  8, 28,  6, 23, 12, 25, 23, 27,  5,  1, 26, 19,\n",
            "        16, 20,  6,  9,  4, 29, 19, 28,  1,  9,  7, 29, 27, 24, 10, 26, 24,  7,\n",
            "        21,  0, 17,  9,  8, 21, 23, 26, 28, 29, 15, 19,  4, 11, 12, 14, 25, 26,\n",
            "        11, 19,  7,  1,  3,  0,  6,  1, 18,  3, 13, 14, 23,  6,  6, 11,  4, 29,\n",
            "        15, 27, 21, 20, 22,  3,  6,  0, 28, 22, 23, 12, 11, 18,  8, 24, 22, 18,\n",
            "        24,  8,  4,  0,  1,  9,  2, 11, 13,  2,  3, 15, 24, 10,  3,  1, 16,  4,\n",
            "        16,  8, 27, 28,  3, 24, 16,  8,  7,  9, 20,  5, 25, 23, 22,  8, 25,  6,\n",
            "        15,  5, 13, 10, 26, 24, 12, 28, 15, 22, 10, 21, 17,  9,  5, 18, 20,  0,\n",
            "        25, 27, 19, 20,  7, 21,  8,  1, 17, 12,  2, 19, 21, 13, 18,  2, 16, 12,\n",
            "         3,  9,  3, 26, 26, 11, 27, 19, 11, 12, 27, 11, 14, 22, 24, 28, 26,  9,\n",
            "         4, 16, 29, 16,  6, 18])\n",
            "tensor([ 2,  8, 19, 29,  7, 22, 12, 28, 29, 11, 24, 27, 12, 20, 25, 12, 27, 18,\n",
            "        23, 22, 19, 22,  9, 12,  2,  1,  0,  1,  0,  4, 18, 18, 22,  3,  2, 11,\n",
            "        24,  9, 14, 29,  5,  6,  8,  9, 21,  5, 18, 26, 14, 10,  7, 15, 25, 23,\n",
            "         7, 27, 16,  5,  6,  0,  2,  8, 26, 29,  3,  5, 17, 18,  2, 22,  9,  4,\n",
            "        26, 17, 28, 17, 19, 25, 27, 16, 17, 14, 18,  3, 14, 15,  1, 22,  8,  3,\n",
            "        20,  3, 13,  1, 20,  0, 29, 25,  8,  2, 14, 13, 12, 17, 20, 13, 11, 15,\n",
            "         5, 21,  8, 28, 24, 10, 10,  1, 14, 29, 11,  6,  6, 28,  5, 26, 14, 20,\n",
            "        25, 17, 28, 22, 16, 23,  5,  3,  4,  0,  1, 14, 16, 11,  5, 17, 12, 25,\n",
            "        28, 16, 11, 18, 26, 10, 11,  7,  3, 23,  9,  1, 20, 27, 13, 14, 23, 19,\n",
            "        16,  4, 14, 18, 11,  3, 16, 28, 20, 24, 10, 14, 20, 18,  2, 24, 13, 14,\n",
            "        25, 15, 23, 13,  4, 13, 22, 22, 19,  5,  0,  7,  6, 15, 15, 29, 13, 20,\n",
            "        10, 27, 29, 28, 19, 16,  5, 10,  0, 10, 29,  9,  0, 28,  9,  0, 13, 15,\n",
            "        23, 20, 23, 26, 10, 12, 11,  9,  0,  4, 15, 19, 21, 14,  8, 15,  4, 27,\n",
            "        10,  7, 19, 12,  6, 19, 14, 23, 19,  1, 12, 29, 10,  9, 13, 19, 17,  4,\n",
            "        13,  4, 10, 29,  7, 21,  8, 16, 12,  3, 29, 20,  6,  4, 16,  9,  1, 24,\n",
            "        23, 17, 20, 15, 13,  7, 18, 26, 14,  7, 24, 29,  4, 20, 25, 21, 22, 26,\n",
            "        25, 17,  2, 11,  1, 10, 14,  5, 18,  0,  8,  7, 25, 19,  9, 26, 22, 23,\n",
            "        14,  1, 15, 21, 13, 26,  7, 27,  4,  1, 29, 17, 21, 11, 29,  4, 27, 21,\n",
            "        24,  4,  7, 25, 21,  2, 15, 10, 17, 24,  1,  5, 12, 28, 16, 14, 23, 13,\n",
            "        21, 13, 23, 26, 24, 10, 27, 27, 16, 12, 11, 18,  9,  7, 19,  8,  0,  6,\n",
            "        20,  3, 11, 25,  2,  5,  6, 10,  5, 28,  8, 21, 15,  6,  6, 12,  6, 22,\n",
            "        12, 17, 15,  0,  2, 12, 24,  5, 18, 17, 22,  7, 10, 19, 23, 24, 16, 15,\n",
            "         0, 13, 20, 25, 27,  3,  0,  4,  3, 21, 21, 25, 18,  7,  5,  7,  2,  2,\n",
            "        27, 28,  2, 22, 12,  2,  8, 28,  6, 23, 12, 25, 23, 27,  5,  1, 26, 17,\n",
            "        16, 20,  6,  9,  4, 29, 19, 28,  1,  9,  7, 29, 27, 24, 10, 26, 24,  7,\n",
            "        21,  0,  6,  9,  8, 18, 23, 26, 28, 28, 15, 19,  4, 11, 12, 28, 29, 26,\n",
            "        11, 19, 27,  1,  3,  0,  6,  1, 18,  3, 13, 14, 23, 17,  6, 11,  4, 29,\n",
            "        15, 27, 21, 21, 22,  3, 17,  0, 28, 22, 23, 12, 10, 18,  8, 24, 22, 18,\n",
            "        24,  8,  4,  0,  1,  9,  2, 11, 13,  2,  3, 15, 24, 16,  3,  1, 16,  4,\n",
            "        16,  8, 17, 25,  3, 24, 16,  8,  7,  9, 11,  5, 28, 23, 22,  8, 25,  6,\n",
            "        15,  5, 13, 10, 26, 24, 12, 26, 15, 22, 20, 21,  6,  9,  5, 25, 20,  0,\n",
            "        25, 27, 19, 20,  7, 21,  8,  1, 17, 21,  2, 17, 21, 13, 18,  2, 16, 20,\n",
            "         3,  9,  3, 26, 26, 11, 27, 19, 11, 19, 27, 25, 14, 22, 24, 28, 26,  9,\n",
            "         2,  8, 29, 16,  6, 18])\n",
            "test accuracy: 0.846667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "train_set = Data.TensorDataset(X_train, Y_train)\n",
        "train_loader = Data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "class LSTM(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(LSTM, self).__init__()\n",
        "        self.fc1 = nn.LSTM(20, 48)\n",
        "        self.fc2 = nn.Linear(48, 96)\n",
        "        self.fc3 = nn.Linear(96, 30)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x, _ = self.fc1(x.view(len(x), 1, -1))\n",
        "        x = self.fc2(x.view(len(x), 48))\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout(self.fc3(x))\n",
        "        \n",
        "        return x\n",
        "    \n",
        "model = LSTM()"
      ],
      "metadata": {
        "id": "tIdpVAumanBX"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 5000\n",
        "learning_rate = 1e-3\n",
        "batch_no = len(X_train) // batch_size\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "Ju8NhA1Cts3S"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    loss_sum = 0\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        y_pred = model(x)\n",
        "        y = y.squeeze()\n",
        "        loss = loss_function(y_pred, y)\n",
        "        loss_sum += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 50 == 0:\n",
        "        print(\"epoch: %d, loss: %f\" % (epoch, loss_sum/batch_size))\n",
        "        acc_sum = 0\n",
        "        acc_sum += (model(X_train).argmax(dim=1) == Y_train.squeeze()).sum()\n",
        "        print(\"train accuracy: %f\" % (acc_sum/len(Y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VNNNp5_twP_",
        "outputId": "b3a3303e-56a0-4697-926c-044837fc3d44"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 50, loss: 0.025782\n",
            "train accuracy: 0.724000\n",
            "epoch: 100, loss: 0.017752\n",
            "train accuracy: 0.788667\n",
            "epoch: 150, loss: 0.013932\n",
            "train accuracy: 0.811333\n",
            "epoch: 200, loss: 0.012252\n",
            "train accuracy: 0.837333\n",
            "epoch: 250, loss: 0.010259\n",
            "train accuracy: 0.853333\n",
            "epoch: 300, loss: 0.009455\n",
            "train accuracy: 0.866667\n",
            "epoch: 350, loss: 0.009074\n",
            "train accuracy: 0.890667\n",
            "epoch: 400, loss: 0.007375\n",
            "train accuracy: 0.884000\n",
            "epoch: 450, loss: 0.008211\n",
            "train accuracy: 0.905333\n",
            "epoch: 500, loss: 0.007175\n",
            "train accuracy: 0.912667\n",
            "epoch: 550, loss: 0.006428\n",
            "train accuracy: 0.896000\n",
            "epoch: 600, loss: 0.006208\n",
            "train accuracy: 0.922000\n",
            "epoch: 650, loss: 0.005605\n",
            "train accuracy: 0.932000\n",
            "epoch: 750, loss: 0.004668\n",
            "train accuracy: 0.920000\n",
            "epoch: 800, loss: 0.004297\n",
            "train accuracy: 0.941333\n",
            "epoch: 850, loss: 0.004262\n",
            "train accuracy: 0.923333\n",
            "epoch: 900, loss: 0.004109\n",
            "train accuracy: 0.923333\n",
            "epoch: 950, loss: 0.003890\n",
            "train accuracy: 0.932000\n",
            "epoch: 1000, loss: 0.004266\n",
            "train accuracy: 0.922000\n",
            "epoch: 1050, loss: 0.003800\n",
            "train accuracy: 0.933333\n",
            "epoch: 1100, loss: 0.004206\n",
            "train accuracy: 0.926000\n",
            "epoch: 1150, loss: 0.003772\n",
            "train accuracy: 0.932000\n",
            "epoch: 1200, loss: 0.003517\n",
            "train accuracy: 0.938000\n",
            "epoch: 1250, loss: 0.003433\n",
            "train accuracy: 0.930000\n",
            "epoch: 1300, loss: 0.003809\n",
            "train accuracy: 0.921333\n",
            "epoch: 1350, loss: 0.003497\n",
            "train accuracy: 0.934667\n",
            "epoch: 1400, loss: 0.003538\n",
            "train accuracy: 0.930667\n",
            "epoch: 1450, loss: 0.003413\n",
            "train accuracy: 0.928000\n",
            "epoch: 1500, loss: 0.002989\n",
            "train accuracy: 0.930667\n",
            "epoch: 1550, loss: 0.003389\n",
            "train accuracy: 0.935333\n",
            "epoch: 1600, loss: 0.003079\n",
            "train accuracy: 0.932667\n",
            "epoch: 1650, loss: 0.003379\n",
            "train accuracy: 0.936667\n",
            "epoch: 1700, loss: 0.003607\n",
            "train accuracy: 0.921333\n",
            "epoch: 1750, loss: 0.003550\n",
            "train accuracy: 0.922667\n",
            "epoch: 1800, loss: 0.003194\n",
            "train accuracy: 0.940000\n",
            "epoch: 1850, loss: 0.003157\n",
            "train accuracy: 0.930000\n",
            "epoch: 1900, loss: 0.003406\n",
            "train accuracy: 0.941333\n",
            "epoch: 1950, loss: 0.003289\n",
            "train accuracy: 0.928000\n",
            "epoch: 2000, loss: 0.003078\n",
            "train accuracy: 0.928667\n",
            "epoch: 2050, loss: 0.002995\n",
            "train accuracy: 0.935333\n",
            "epoch: 2100, loss: 0.002943\n",
            "train accuracy: 0.935333\n",
            "epoch: 2150, loss: 0.003586\n",
            "train accuracy: 0.936667\n",
            "epoch: 2200, loss: 0.003432\n",
            "train accuracy: 0.934667\n",
            "epoch: 2250, loss: 0.002721\n",
            "train accuracy: 0.933333\n",
            "epoch: 2300, loss: 0.003090\n",
            "train accuracy: 0.936000\n",
            "epoch: 2350, loss: 0.003028\n",
            "train accuracy: 0.927333\n",
            "epoch: 2400, loss: 0.002918\n",
            "train accuracy: 0.929333\n",
            "epoch: 2450, loss: 0.003103\n",
            "train accuracy: 0.926667\n",
            "epoch: 2500, loss: 0.002860\n",
            "train accuracy: 0.930000\n",
            "epoch: 2550, loss: 0.003076\n",
            "train accuracy: 0.926000\n",
            "epoch: 2600, loss: 0.003264\n",
            "train accuracy: 0.934667\n",
            "epoch: 2650, loss: 0.003494\n",
            "train accuracy: 0.939333\n",
            "epoch: 2700, loss: 0.003372\n",
            "train accuracy: 0.924667\n",
            "epoch: 2750, loss: 0.003440\n",
            "train accuracy: 0.940000\n",
            "epoch: 2800, loss: 0.003396\n",
            "train accuracy: 0.938000\n",
            "epoch: 2850, loss: 0.003057\n",
            "train accuracy: 0.936667\n",
            "epoch: 2900, loss: 0.003701\n",
            "train accuracy: 0.928667\n",
            "epoch: 2950, loss: 0.003066\n",
            "train accuracy: 0.936000\n",
            "epoch: 3000, loss: 0.002939\n",
            "train accuracy: 0.936000\n",
            "epoch: 3050, loss: 0.002834\n",
            "train accuracy: 0.941333\n",
            "epoch: 3100, loss: 0.003418\n",
            "train accuracy: 0.936667\n",
            "epoch: 3150, loss: 0.002771\n",
            "train accuracy: 0.932000\n",
            "epoch: 3200, loss: 0.003246\n",
            "train accuracy: 0.938667\n",
            "epoch: 3250, loss: 0.003275\n",
            "train accuracy: 0.934667\n",
            "epoch: 3300, loss: 0.003013\n",
            "train accuracy: 0.927333\n",
            "epoch: 3350, loss: 0.003053\n",
            "train accuracy: 0.931333\n",
            "epoch: 3400, loss: 0.003185\n",
            "train accuracy: 0.925333\n",
            "epoch: 3450, loss: 0.003147\n",
            "train accuracy: 0.931333\n",
            "epoch: 3500, loss: 0.003089\n",
            "train accuracy: 0.940000\n",
            "epoch: 3550, loss: 0.002829\n",
            "train accuracy: 0.929333\n",
            "epoch: 3600, loss: 0.003724\n",
            "train accuracy: 0.934000\n",
            "epoch: 3650, loss: 0.002944\n",
            "train accuracy: 0.930667\n",
            "epoch: 3700, loss: 0.002972\n",
            "train accuracy: 0.930000\n",
            "epoch: 3750, loss: 0.002974\n",
            "train accuracy: 0.928000\n",
            "epoch: 3800, loss: 0.003186\n",
            "train accuracy: 0.939333\n",
            "epoch: 3850, loss: 0.002328\n",
            "train accuracy: 0.926000\n",
            "epoch: 3900, loss: 0.002971\n",
            "train accuracy: 0.935333\n",
            "epoch: 3950, loss: 0.003257\n",
            "train accuracy: 0.925333\n",
            "epoch: 4000, loss: 0.002600\n",
            "train accuracy: 0.937333\n",
            "epoch: 4050, loss: 0.002916\n",
            "train accuracy: 0.928667\n",
            "epoch: 4100, loss: 0.002832\n",
            "train accuracy: 0.925333\n",
            "epoch: 4150, loss: 0.002960\n",
            "train accuracy: 0.924000\n",
            "epoch: 4200, loss: 0.003136\n",
            "train accuracy: 0.928000\n",
            "epoch: 4250, loss: 0.002982\n",
            "train accuracy: 0.914000\n",
            "epoch: 4300, loss: 0.003047\n",
            "train accuracy: 0.925333\n",
            "epoch: 4350, loss: 0.002935\n",
            "train accuracy: 0.930667\n",
            "epoch: 4400, loss: 0.002922\n",
            "train accuracy: 0.933333\n",
            "epoch: 4450, loss: 0.003234\n",
            "train accuracy: 0.945333\n",
            "epoch: 4500, loss: 0.003021\n",
            "train accuracy: 0.917333\n",
            "epoch: 4550, loss: 0.003047\n",
            "train accuracy: 0.931333\n",
            "epoch: 4600, loss: 0.003081\n",
            "train accuracy: 0.932667\n",
            "epoch: 4650, loss: 0.003297\n",
            "train accuracy: 0.929333\n",
            "epoch: 4700, loss: 0.002674\n",
            "train accuracy: 0.934667\n",
            "epoch: 4750, loss: 0.003276\n",
            "train accuracy: 0.934667\n",
            "epoch: 4800, loss: 0.002793\n",
            "train accuracy: 0.944000\n",
            "epoch: 4850, loss: 0.002747\n",
            "train accuracy: 0.933333\n",
            "epoch: 4900, loss: 0.002351\n",
            "train accuracy: 0.933333\n",
            "epoch: 4950, loss: 0.003069\n",
            "train accuracy: 0.919333\n",
            "epoch: 5000, loss: 0.003249\n",
            "train accuracy: 0.947333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "acc_sum = 0\n",
        "print(model(X_test).argmax(dim=1))\n",
        "print(Y_test.squeeze())\n",
        "acc_sum += (model(X_test.view(len(X_test), 1, -1)).argmax(dim=1) == Y_test.squeeze()).sum()\n",
        "print(\"test accuracy: %f\" % (acc_sum/len(Y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hT54C4_wtyWI",
        "outputId": "35f3f4f1-4a0b-44fa-fba6-6ee6a3876c4d"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  8, 19, 29,  7, 22, 12, 28, 29, 10, 24, 27, 23,  0, 25, 12, 27, 18,\n",
            "        23, 22, 19, 22,  9, 12,  2,  1,  0,  1,  0,  4, 18, 21, 22, 14,  2, 11,\n",
            "        24,  9, 14, 29,  5,  6,  8,  9, 21,  5, 18, 26, 14, 27,  7, 22, 25, 23,\n",
            "         7, 27, 16,  5,  6,  0,  2,  8, 26, 27, 14,  5, 17, 18,  2, 22,  9,  4,\n",
            "        12, 17, 28, 11, 19, 28, 27, 16, 17, 14, 18,  3, 14, 15, 23, 22,  8, 14,\n",
            "        20,  3, 13, 14, 20,  0, 29, 15,  8,  2, 14, 13, 12, 18, 20, 13, 11, 15,\n",
            "         5, 21,  8, 28, 24, 10, 10,  1, 14, 19, 11,  6,  6, 28,  5, 26, 14, 20,\n",
            "        11, 17, 28, 22, 16, 23,  5,  3,  4,  0,  1,  3, 16, 11,  5,  6, 12, 26,\n",
            "        28, 16, 11, 18, 26, 10, 11,  7,  3, 23,  9,  1, 10, 27, 13, 14, 23, 19,\n",
            "        21,  4, 14,  3, 11,  3, 16, 24, 12, 24, 10, 14, 25, 18,  2, 24, 13, 14,\n",
            "        18, 15, 23, 13,  4, 13, 22, 22, 19,  4,  0,  7,  6, 22, 15, 29, 13, 20,\n",
            "        10, 27, 29, 28, 19, 16,  5, 27,  0, 10, 29,  9,  0, 28,  9,  0, 13, 15,\n",
            "        23, 20, 23, 26, 10, 12, 11,  9,  0,  4, 15, 19, 21, 14,  8, 22,  4, 27,\n",
            "        11,  7, 19, 19, 27, 19, 14, 23, 19,  1, 12, 29, 10,  9, 13, 19, 17,  4,\n",
            "        13,  4, 10, 29,  7, 12,  8, 16, 18,  3, 29, 20,  6, 27, 16,  9,  8, 24,\n",
            "        23, 27, 20, 15, 13,  7, 11, 12, 14,  7, 24, 29,  4, 20, 27, 20, 22, 26,\n",
            "        21, 17,  2, 11,  1, 10, 14,  5, 18,  0,  8,  7, 22, 19,  9, 26, 22, 23,\n",
            "        14,  1, 15, 21, 13, 26,  7, 27,  4,  1, 29, 17, 21, 11, 17,  4,  4, 21,\n",
            "        24,  4,  7, 24, 12,  2, 15, 11, 17, 24,  1,  5, 12, 28, 16, 14, 23, 13,\n",
            "        21, 13, 13, 26, 24, 27, 27, 27, 16, 12, 11, 18,  9,  7, 19,  8,  0,  6,\n",
            "        20,  3, 11, 25,  2,  5, 17, 10,  5, 28,  8, 21, 15,  6, 17, 12,  6, 22,\n",
            "        12, 17, 11,  0,  2, 12, 24,  5, 18, 25, 22,  7, 18, 19, 23, 24, 16, 27,\n",
            "         0, 13, 20, 25, 27,  3,  0,  6,  3, 21, 21, 25, 18,  7,  5,  7,  2,  2,\n",
            "        27, 28,  2, 22, 16,  2,  8, 28,  6, 23, 12, 25, 23, 27,  5,  1, 26,  6,\n",
            "        16, 20,  6,  9,  4, 29, 19, 25,  1,  9,  7, 29, 27, 24, 10, 26, 24,  7,\n",
            "        21,  0, 17,  9,  8, 21, 23, 26, 28, 29, 15, 19,  4, 11, 28, 14, 25, 26,\n",
            "        20, 19,  7,  1,  3,  0,  6,  1, 18,  3, 13, 14, 23, 19,  6, 22,  4, 29,\n",
            "        15, 27, 21, 21, 22,  3,  6,  0, 28, 22, 23, 12, 18, 18,  8, 24, 22, 18,\n",
            "        24,  8,  4,  0,  1,  9,  2,  6, 25,  2,  3, 15, 24, 16,  3,  1, 16,  4,\n",
            "        16,  8, 27, 25,  3, 24, 16,  8,  7,  9, 20,  5, 25, 23, 22,  8, 25,  6,\n",
            "        15,  5,  4,  3, 26, 24, 12, 28, 10, 22, 20, 16, 17,  9,  5, 18, 20,  0,\n",
            "        25, 27, 19, 20,  7,  0,  8,  1, 17, 12,  2, 19, 21, 13, 18,  5, 16, 20,\n",
            "         3,  9,  3, 26, 26, 11, 27, 19, 11, 19, 27, 11, 14, 22, 24, 28, 26,  9,\n",
            "         2,  8, 29, 16,  6, 18])\n",
            "tensor([ 2,  8, 19, 29,  7, 22, 12, 28, 29, 11, 24, 27, 12, 20, 25, 12, 27, 18,\n",
            "        23, 22, 19, 22,  9, 12,  2,  1,  0,  1,  0,  4, 18, 18, 22,  3,  2, 11,\n",
            "        24,  9, 14, 29,  5,  6,  8,  9, 21,  5, 18, 26, 14, 10,  7, 15, 25, 23,\n",
            "         7, 27, 16,  5,  6,  0,  2,  8, 26, 29,  3,  5, 17, 18,  2, 22,  9,  4,\n",
            "        26, 17, 28, 17, 19, 25, 27, 16, 17, 14, 18,  3, 14, 15,  1, 22,  8,  3,\n",
            "        20,  3, 13,  1, 20,  0, 29, 25,  8,  2, 14, 13, 12, 17, 20, 13, 11, 15,\n",
            "         5, 21,  8, 28, 24, 10, 10,  1, 14, 29, 11,  6,  6, 28,  5, 26, 14, 20,\n",
            "        25, 17, 28, 22, 16, 23,  5,  3,  4,  0,  1, 14, 16, 11,  5, 17, 12, 25,\n",
            "        28, 16, 11, 18, 26, 10, 11,  7,  3, 23,  9,  1, 20, 27, 13, 14, 23, 19,\n",
            "        16,  4, 14, 18, 11,  3, 16, 28, 20, 24, 10, 14, 20, 18,  2, 24, 13, 14,\n",
            "        25, 15, 23, 13,  4, 13, 22, 22, 19,  5,  0,  7,  6, 15, 15, 29, 13, 20,\n",
            "        10, 27, 29, 28, 19, 16,  5, 10,  0, 10, 29,  9,  0, 28,  9,  0, 13, 15,\n",
            "        23, 20, 23, 26, 10, 12, 11,  9,  0,  4, 15, 19, 21, 14,  8, 15,  4, 27,\n",
            "        10,  7, 19, 12,  6, 19, 14, 23, 19,  1, 12, 29, 10,  9, 13, 19, 17,  4,\n",
            "        13,  4, 10, 29,  7, 21,  8, 16, 12,  3, 29, 20,  6,  4, 16,  9,  1, 24,\n",
            "        23, 17, 20, 15, 13,  7, 18, 26, 14,  7, 24, 29,  4, 20, 25, 21, 22, 26,\n",
            "        25, 17,  2, 11,  1, 10, 14,  5, 18,  0,  8,  7, 25, 19,  9, 26, 22, 23,\n",
            "        14,  1, 15, 21, 13, 26,  7, 27,  4,  1, 29, 17, 21, 11, 29,  4, 27, 21,\n",
            "        24,  4,  7, 25, 21,  2, 15, 10, 17, 24,  1,  5, 12, 28, 16, 14, 23, 13,\n",
            "        21, 13, 23, 26, 24, 10, 27, 27, 16, 12, 11, 18,  9,  7, 19,  8,  0,  6,\n",
            "        20,  3, 11, 25,  2,  5,  6, 10,  5, 28,  8, 21, 15,  6,  6, 12,  6, 22,\n",
            "        12, 17, 15,  0,  2, 12, 24,  5, 18, 17, 22,  7, 10, 19, 23, 24, 16, 15,\n",
            "         0, 13, 20, 25, 27,  3,  0,  4,  3, 21, 21, 25, 18,  7,  5,  7,  2,  2,\n",
            "        27, 28,  2, 22, 12,  2,  8, 28,  6, 23, 12, 25, 23, 27,  5,  1, 26, 17,\n",
            "        16, 20,  6,  9,  4, 29, 19, 28,  1,  9,  7, 29, 27, 24, 10, 26, 24,  7,\n",
            "        21,  0,  6,  9,  8, 18, 23, 26, 28, 28, 15, 19,  4, 11, 12, 28, 29, 26,\n",
            "        11, 19, 27,  1,  3,  0,  6,  1, 18,  3, 13, 14, 23, 17,  6, 11,  4, 29,\n",
            "        15, 27, 21, 21, 22,  3, 17,  0, 28, 22, 23, 12, 10, 18,  8, 24, 22, 18,\n",
            "        24,  8,  4,  0,  1,  9,  2, 11, 13,  2,  3, 15, 24, 16,  3,  1, 16,  4,\n",
            "        16,  8, 17, 25,  3, 24, 16,  8,  7,  9, 11,  5, 28, 23, 22,  8, 25,  6,\n",
            "        15,  5, 13, 10, 26, 24, 12, 26, 15, 22, 20, 21,  6,  9,  5, 25, 20,  0,\n",
            "        25, 27, 19, 20,  7, 21,  8,  1, 17, 21,  2, 17, 21, 13, 18,  2, 16, 20,\n",
            "         3,  9,  3, 26, 26, 11, 27, 19, 11, 19, 27, 25, 14, 22, 24, 28, 26,  9,\n",
            "         2,  8, 29, 16,  6, 18])\n",
            "test accuracy: 0.845000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = pd.read_csv('./train.csv')\n",
        "testset = pd.read_csv('./test.csv')\n",
        "\n",
        "print(trainset)\n",
        "print(testset)\n",
        "\n",
        "X_train = trainset.iloc[:, 0:20].values\n",
        "Y_train = trainset.iloc[:, 20].values\n",
        "Y_train = Y_train-1\n",
        "\n",
        "X_test = testset.iloc[:, 0:20].values\n",
        "Y_test = testset.iloc[:, 20].values\n",
        "Y_test = Y_test-1\n",
        "\n",
        "X_train = torch.from_numpy(X_train).type(torch.FloatTensor)\n",
        "Y_train = torch.from_numpy(Y_train).type(torch.LongTensor)\n",
        "X_test = torch.from_numpy(X_test).type(torch.FloatTensor)\n",
        "Y_test = torch.from_numpy(Y_test).type(torch.LongTensor)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOqiCT7lztYp",
        "outputId": "c86d4aad-dbcf-4b7d-e4f3-96e99bf35f41"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      cache-misses-1  node-loads-1  ...  branch-load-misses-5  label\n",
            "0           36218220       2530196  ...              17816426      7\n",
            "1           34025893       2310966  ...              38927513     23\n",
            "2           36778380       2597194  ...              18699857     17\n",
            "3           35736215       2499164  ...              19137869     12\n",
            "4           33763999       2342137  ...              19270653     24\n",
            "...              ...           ...  ...                   ...    ...\n",
            "1495        32765499       2249790  ...              16673701     26\n",
            "1496        36032964       2675011  ...              16989614      1\n",
            "1497        34176184       2447644  ...              17000473      1\n",
            "1498        32203221       2189984  ...              17285080     26\n",
            "1499        34253061       2361245  ...              17671581     13\n",
            "\n",
            "[1500 rows x 21 columns]\n",
            "     cache-misses-1  node-loads-1  ...  branch-load-misses-5  label\n",
            "0          33534639       2368872  ...              22351242      3\n",
            "1          32232524       2183296  ...              24357368      9\n",
            "2          33022157       2301241  ...              16859615     20\n",
            "3          30530041       2055189  ...              17478380     30\n",
            "4          34681266       2432101  ...              19423388      8\n",
            "..              ...           ...  ...                   ...    ...\n",
            "595        31676766       2147940  ...              18798197      9\n",
            "596        38171975       2742669  ...              17275995     30\n",
            "597        32279778       2202587  ...              17590848     17\n",
            "598        35783099       2524731  ...              19007292      7\n",
            "599        33492002       2357476  ...              34302105     19\n",
            "\n",
            "[600 rows x 21 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 512\n",
        "train_set = Data.TensorDataset(X_train, Y_train)\n",
        "train_loader = Data.DataLoader(\n",
        "    dataset=train_set,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "model = MLP()\n",
        "\n",
        "num_epochs = 5000\n",
        "learning_rate = 1e-3\n",
        "batch_no = len(X_train) // batch_size\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "loss_function = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "TzIYsluVE3Cf"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in range(1, num_epochs+1):\n",
        "    loss_sum = 0\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        y_pred = model(x)\n",
        "        y = y.squeeze()\n",
        "        loss = loss_function(y_pred, y)\n",
        "        loss_sum += loss\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    if epoch % 50 == 0:\n",
        "        print(\"epoch: %d, loss: %f\" % (epoch, loss_sum/batch_size))\n",
        "        acc_sum = 0\n",
        "        acc_sum += (model(X_train).argmax(dim=1) == Y_train.squeeze()).sum()\n",
        "        print(\"train accuracy: %f\" % (acc_sum/len(Y_train)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "etVGYoQHE_xo",
        "outputId": "5555ed6c-89a6-4a02-ca99-aec1d2a0cf03"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 50, loss: 45.865765\n",
            "train accuracy: 0.540667\n",
            "epoch: 100, loss: 28.005024\n",
            "train accuracy: 0.656000\n",
            "epoch: 150, loss: 22.214424\n",
            "train accuracy: 0.654000\n",
            "epoch: 200, loss: 14.174532\n",
            "train accuracy: 0.717333\n",
            "epoch: 250, loss: 13.027711\n",
            "train accuracy: 0.690667\n",
            "epoch: 300, loss: 8.891039\n",
            "train accuracy: 0.756000\n",
            "epoch: 350, loss: 13.349325\n",
            "train accuracy: 0.721333\n",
            "epoch: 400, loss: 5.510678\n",
            "train accuracy: 0.794667\n",
            "epoch: 450, loss: 7.459725\n",
            "train accuracy: 0.784000\n",
            "epoch: 500, loss: 5.469628\n",
            "train accuracy: 0.823333\n",
            "epoch: 550, loss: 5.552497\n",
            "train accuracy: 0.792000\n",
            "epoch: 600, loss: 4.666986\n",
            "train accuracy: 0.812667\n",
            "epoch: 650, loss: 4.334311\n",
            "train accuracy: 0.827333\n",
            "epoch: 700, loss: 3.565736\n",
            "train accuracy: 0.844667\n",
            "epoch: 750, loss: 2.944563\n",
            "train accuracy: 0.829333\n",
            "epoch: 800, loss: 2.598421\n",
            "train accuracy: 0.815333\n",
            "epoch: 850, loss: 3.681266\n",
            "train accuracy: 0.838667\n",
            "epoch: 900, loss: 2.253383\n",
            "train accuracy: 0.834000\n",
            "epoch: 950, loss: 2.158818\n",
            "train accuracy: 0.833333\n",
            "epoch: 1000, loss: 1.936796\n",
            "train accuracy: 0.822667\n",
            "epoch: 1050, loss: 2.449601\n",
            "train accuracy: 0.840667\n",
            "epoch: 1100, loss: 1.618738\n",
            "train accuracy: 0.874000\n",
            "epoch: 1150, loss: 1.878982\n",
            "train accuracy: 0.872000\n",
            "epoch: 1200, loss: 1.837657\n",
            "train accuracy: 0.873333\n",
            "epoch: 1250, loss: 0.958700\n",
            "train accuracy: 0.882667\n",
            "epoch: 1300, loss: 2.033909\n",
            "train accuracy: 0.863333\n",
            "epoch: 1350, loss: 1.575292\n",
            "train accuracy: 0.832000\n",
            "epoch: 1400, loss: 1.201599\n",
            "train accuracy: 0.872667\n",
            "epoch: 1450, loss: 2.733081\n",
            "train accuracy: 0.850000\n",
            "epoch: 1500, loss: 1.865166\n",
            "train accuracy: 0.843333\n",
            "epoch: 1550, loss: 0.791351\n",
            "train accuracy: 0.902667\n",
            "epoch: 1600, loss: 1.279051\n",
            "train accuracy: 0.867333\n",
            "epoch: 1650, loss: 0.695714\n",
            "train accuracy: 0.906000\n",
            "epoch: 1700, loss: 0.574392\n",
            "train accuracy: 0.890667\n",
            "epoch: 1750, loss: 0.923908\n",
            "train accuracy: 0.896000\n",
            "epoch: 1800, loss: 0.650948\n",
            "train accuracy: 0.872667\n",
            "epoch: 1850, loss: 0.821769\n",
            "train accuracy: 0.898000\n",
            "epoch: 1900, loss: 1.271662\n",
            "train accuracy: 0.876000\n",
            "epoch: 1950, loss: 0.584096\n",
            "train accuracy: 0.902000\n",
            "epoch: 2000, loss: 0.688220\n",
            "train accuracy: 0.887333\n",
            "epoch: 2050, loss: 0.870992\n",
            "train accuracy: 0.902000\n",
            "epoch: 2100, loss: 0.554554\n",
            "train accuracy: 0.880000\n",
            "epoch: 2150, loss: 0.753468\n",
            "train accuracy: 0.896000\n",
            "epoch: 2200, loss: 1.048355\n",
            "train accuracy: 0.902667\n",
            "epoch: 2250, loss: 1.149931\n",
            "train accuracy: 0.862000\n",
            "epoch: 2300, loss: 0.509904\n",
            "train accuracy: 0.896667\n",
            "epoch: 2350, loss: 0.726109\n",
            "train accuracy: 0.883333\n",
            "epoch: 2400, loss: 0.546269\n",
            "train accuracy: 0.888667\n",
            "epoch: 2450, loss: 1.121247\n",
            "train accuracy: 0.909333\n",
            "epoch: 2500, loss: 0.856457\n",
            "train accuracy: 0.905333\n",
            "epoch: 2550, loss: 1.056039\n",
            "train accuracy: 0.910000\n",
            "epoch: 2600, loss: 0.311827\n",
            "train accuracy: 0.914000\n",
            "epoch: 2650, loss: 0.533973\n",
            "train accuracy: 0.916000\n",
            "epoch: 2700, loss: 0.547686\n",
            "train accuracy: 0.892000\n",
            "epoch: 2750, loss: 0.502703\n",
            "train accuracy: 0.916000\n",
            "epoch: 2800, loss: 1.416002\n",
            "train accuracy: 0.872000\n",
            "epoch: 2850, loss: 0.304860\n",
            "train accuracy: 0.918000\n",
            "epoch: 2900, loss: 0.667831\n",
            "train accuracy: 0.876000\n",
            "epoch: 2950, loss: 0.865528\n",
            "train accuracy: 0.894667\n",
            "epoch: 3000, loss: 0.429179\n",
            "train accuracy: 0.880000\n",
            "epoch: 3050, loss: 0.264352\n",
            "train accuracy: 0.908000\n",
            "epoch: 3100, loss: 0.535652\n",
            "train accuracy: 0.894667\n",
            "epoch: 3150, loss: 0.336466\n",
            "train accuracy: 0.900000\n",
            "epoch: 3200, loss: 0.543526\n",
            "train accuracy: 0.893333\n",
            "epoch: 3250, loss: 0.600885\n",
            "train accuracy: 0.902000\n",
            "epoch: 3300, loss: 0.096753\n",
            "train accuracy: 0.918000\n",
            "epoch: 3350, loss: 0.120586\n",
            "train accuracy: 0.925333\n",
            "epoch: 3400, loss: 3.138459\n",
            "train accuracy: 0.823333\n",
            "epoch: 3450, loss: 0.166287\n",
            "train accuracy: 0.931333\n",
            "epoch: 3500, loss: 0.089152\n",
            "train accuracy: 0.917333\n",
            "epoch: 3550, loss: 0.308989\n",
            "train accuracy: 0.916000\n",
            "epoch: 3600, loss: 1.617127\n",
            "train accuracy: 0.880000\n",
            "epoch: 3650, loss: 0.397096\n",
            "train accuracy: 0.903333\n",
            "epoch: 3700, loss: 0.087968\n",
            "train accuracy: 0.920667\n",
            "epoch: 3750, loss: 0.262957\n",
            "train accuracy: 0.918667\n",
            "epoch: 3800, loss: 0.415278\n",
            "train accuracy: 0.898000\n",
            "epoch: 3850, loss: 0.609719\n",
            "train accuracy: 0.892667\n",
            "epoch: 3900, loss: 0.196093\n",
            "train accuracy: 0.921333\n",
            "epoch: 3950, loss: 0.766523\n",
            "train accuracy: 0.879333\n",
            "epoch: 4000, loss: 0.450742\n",
            "train accuracy: 0.889333\n",
            "epoch: 4050, loss: 0.802897\n",
            "train accuracy: 0.872000\n",
            "epoch: 4100, loss: 0.221594\n",
            "train accuracy: 0.900667\n",
            "epoch: 4150, loss: 0.108309\n",
            "train accuracy: 0.921333\n",
            "epoch: 4200, loss: 0.057778\n",
            "train accuracy: 0.932667\n",
            "epoch: 4250, loss: 0.059213\n",
            "train accuracy: 0.918667\n",
            "epoch: 4300, loss: 0.006875\n",
            "train accuracy: 0.921333\n",
            "epoch: 4350, loss: 1.055243\n",
            "train accuracy: 0.906000\n",
            "epoch: 4400, loss: 0.350956\n",
            "train accuracy: 0.921333\n",
            "epoch: 4450, loss: 0.016287\n",
            "train accuracy: 0.913333\n",
            "epoch: 4500, loss: 0.046530\n",
            "train accuracy: 0.928667\n",
            "epoch: 4550, loss: 0.229812\n",
            "train accuracy: 0.895333\n",
            "epoch: 4600, loss: 0.283282\n",
            "train accuracy: 0.916000\n",
            "epoch: 4650, loss: 0.090378\n",
            "train accuracy: 0.930000\n",
            "epoch: 4700, loss: 0.135879\n",
            "train accuracy: 0.912000\n",
            "epoch: 4750, loss: 2.181007\n",
            "train accuracy: 0.840000\n",
            "epoch: 4800, loss: 0.039329\n",
            "train accuracy: 0.922667\n",
            "epoch: 4850, loss: 0.036520\n",
            "train accuracy: 0.932667\n",
            "epoch: 4900, loss: 0.096729\n",
            "train accuracy: 0.936000\n",
            "epoch: 4950, loss: 0.084552\n",
            "train accuracy: 0.913333\n",
            "epoch: 5000, loss: 0.029374\n",
            "train accuracy: 0.935333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "acc_sum = 0\n",
        "print(model(X_test).argmax(dim=1))\n",
        "print(Y_test.squeeze())\n",
        "acc_sum += (model(X_test).argmax(dim=1) == Y_test.squeeze()).sum()\n",
        "print(\"test accuracy: %f\" % (acc_sum/len(Y_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sB5Yj5beFAw5",
        "outputId": "8dccfe25-d913-484a-d168-66d5a6d32505"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 2,  8, 19, 29,  7, 22, 26, 24, 25, 11, 24, 17, 20, 20, 29, 16, 17, 18,\n",
            "        23, 22, 19, 22,  9, 26,  2,  1,  0,  1,  0,  4, 18, 18, 22,  3,  2,  6,\n",
            "        24,  9, 14, 29,  5, 11,  8,  9, 21,  5, 18, 26, 14, 27,  7,  7, 25, 23,\n",
            "         7, 27, 16,  5,  6,  0,  2,  8, 26, 18,  3,  5, 27, 18,  2, 22,  9,  4,\n",
            "        26, 17, 28, 11, 19, 14, 27, 16, 17, 14, 18,  3, 14, 15, 28, 22,  8,  3,\n",
            "        20,  3, 13,  1, 20,  0, 29, 15,  8,  2, 14, 11, 17, 17, 20, 25, 15, 15,\n",
            "         5, 21,  8, 28, 24, 10,  8,  1, 14, 17, 11,  6,  6, 28,  5, 26, 14, 20,\n",
            "        11,  6, 28,  8, 12, 23,  5,  3,  4,  0,  1,  3, 16, 11,  5,  6, 26, 26,\n",
            "        28, 21, 25, 18, 12, 10, 11,  7,  3, 23,  9,  1, 27, 27, 13, 14, 23, 19,\n",
            "        20,  4, 14, 18, 11,  3, 16, 24, 12, 24, 10, 14, 11, 18,  2, 22, 11, 14,\n",
            "        18, 15, 23, 13,  5, 13, 22, 22, 19,  5,  0,  7,  6, 22, 15, 29, 13, 20,\n",
            "        10, 27, 24,  8, 19, 12,  5, 17,  0, 10, 29,  9,  0, 28,  9,  0, 15, 15,\n",
            "        23, 20, 23, 26, 10, 12, 11,  9,  0,  4, 15, 19, 21, 14,  8, 22,  4, 27,\n",
            "        10, 27, 17, 19, 17, 19, 14, 23, 17,  1, 21, 29, 15,  9, 13, 19, 17,  4,\n",
            "        13,  4, 10, 29,  7, 12,  8, 12, 18,  3, 29, 10,  6, 19, 16,  9, 16, 24,\n",
            "        23, 27, 20, 15, 13,  7, 18, 11, 14,  7, 24, 29,  4, 20, 27, 12, 22, 26,\n",
            "        18, 17,  2, 15,  1, 10, 14,  5, 18,  0,  8,  7, 22, 19,  9, 21, 22, 11,\n",
            "         3,  1, 15, 21, 13, 26,  7,  7,  4,  1, 29, 17, 21, 11, 17,  4,  4, 21,\n",
            "        24,  4,  7, 22, 21,  2, 15,  7, 17, 24,  1,  5, 12, 28, 16, 14, 25, 13,\n",
            "        21, 13, 13, 26, 24,  7, 27, 27, 16, 12, 11, 18,  9,  7, 19,  8,  0, 17,\n",
            "        26,  3, 11, 29,  2,  5, 17, 10,  5, 28,  8,  3, 11,  6, 17, 28,  6, 22,\n",
            "        12, 17, 11,  0,  2, 21, 24,  5, 18, 17, 22,  7, 10, 19, 23, 24, 12, 11,\n",
            "         0, 13, 20,  2, 27,  3,  0, 27,  3, 18, 21, 25, 18,  7,  5,  7,  2,  2,\n",
            "        27, 28,  2, 22, 26,  2, 12, 28,  6, 23, 12, 25, 23, 27,  5, 25, 26,  6,\n",
            "        12, 20,  6,  9,  4, 29, 19, 28,  1,  9,  7, 29, 17, 24, 10, 21, 24,  7,\n",
            "        21,  0, 17,  9,  8, 21, 23, 26, 28, 28, 15, 19,  4, 11, 12, 28, 29, 21,\n",
            "        11, 19,  7,  1,  3,  0,  6,  1, 18,  3, 13, 14, 23,  6,  6, 25,  4, 29,\n",
            "        15, 27, 21, 12, 26,  3, 17,  0, 28, 22, 23, 12, 27, 18,  8, 24, 22, 18,\n",
            "        24,  8,  4,  0,  1,  9,  2, 11, 17,  2,  3, 15, 24, 21,  3,  1, 16,  4,\n",
            "        21,  8, 17, 12,  3, 24, 21,  8,  7,  9, 11,  5, 29, 23, 24,  1, 25,  6,\n",
            "        15,  5, 13, 10, 26, 24, 12, 23, 15, 22, 20, 21, 17,  9,  5, 21, 20,  0,\n",
            "        11, 27, 19, 20,  7, 21,  8,  1,  9, 28,  2, 19, 21, 13, 18,  4, 16, 21,\n",
            "         3,  9,  3, 26, 26, 11, 27, 19, 11, 12, 27, 11, 14, 22, 24, 28, 26,  9,\n",
            "         2,  8, 29, 28,  6, 18])\n",
            "tensor([ 2,  8, 19, 29,  7, 22, 12, 28, 29, 11, 24, 27, 12, 20, 25, 12, 27, 18,\n",
            "        23, 22, 19, 22,  9, 12,  2,  1,  0,  1,  0,  4, 18, 18, 22,  3,  2, 11,\n",
            "        24,  9, 14, 29,  5,  6,  8,  9, 21,  5, 18, 26, 14, 10,  7, 15, 25, 23,\n",
            "         7, 27, 16,  5,  6,  0,  2,  8, 26, 29,  3,  5, 17, 18,  2, 22,  9,  4,\n",
            "        26, 17, 28, 17, 19, 25, 27, 16, 17, 14, 18,  3, 14, 15,  1, 22,  8,  3,\n",
            "        20,  3, 13,  1, 20,  0, 29, 25,  8,  2, 14, 13, 12, 17, 20, 13, 11, 15,\n",
            "         5, 21,  8, 28, 24, 10, 10,  1, 14, 29, 11,  6,  6, 28,  5, 26, 14, 20,\n",
            "        25, 17, 28, 22, 16, 23,  5,  3,  4,  0,  1, 14, 16, 11,  5, 17, 12, 25,\n",
            "        28, 16, 11, 18, 26, 10, 11,  7,  3, 23,  9,  1, 20, 27, 13, 14, 23, 19,\n",
            "        16,  4, 14, 18, 11,  3, 16, 28, 20, 24, 10, 14, 20, 18,  2, 24, 13, 14,\n",
            "        25, 15, 23, 13,  4, 13, 22, 22, 19,  5,  0,  7,  6, 15, 15, 29, 13, 20,\n",
            "        10, 27, 29, 28, 19, 16,  5, 10,  0, 10, 29,  9,  0, 28,  9,  0, 13, 15,\n",
            "        23, 20, 23, 26, 10, 12, 11,  9,  0,  4, 15, 19, 21, 14,  8, 15,  4, 27,\n",
            "        10,  7, 19, 12,  6, 19, 14, 23, 19,  1, 12, 29, 10,  9, 13, 19, 17,  4,\n",
            "        13,  4, 10, 29,  7, 21,  8, 16, 12,  3, 29, 20,  6,  4, 16,  9,  1, 24,\n",
            "        23, 17, 20, 15, 13,  7, 18, 26, 14,  7, 24, 29,  4, 20, 25, 21, 22, 26,\n",
            "        25, 17,  2, 11,  1, 10, 14,  5, 18,  0,  8,  7, 25, 19,  9, 26, 22, 23,\n",
            "        14,  1, 15, 21, 13, 26,  7, 27,  4,  1, 29, 17, 21, 11, 29,  4, 27, 21,\n",
            "        24,  4,  7, 25, 21,  2, 15, 10, 17, 24,  1,  5, 12, 28, 16, 14, 23, 13,\n",
            "        21, 13, 23, 26, 24, 10, 27, 27, 16, 12, 11, 18,  9,  7, 19,  8,  0,  6,\n",
            "        20,  3, 11, 25,  2,  5,  6, 10,  5, 28,  8, 21, 15,  6,  6, 12,  6, 22,\n",
            "        12, 17, 15,  0,  2, 12, 24,  5, 18, 17, 22,  7, 10, 19, 23, 24, 16, 15,\n",
            "         0, 13, 20, 25, 27,  3,  0,  4,  3, 21, 21, 25, 18,  7,  5,  7,  2,  2,\n",
            "        27, 28,  2, 22, 12,  2,  8, 28,  6, 23, 12, 25, 23, 27,  5,  1, 26, 17,\n",
            "        16, 20,  6,  9,  4, 29, 19, 28,  1,  9,  7, 29, 27, 24, 10, 26, 24,  7,\n",
            "        21,  0,  6,  9,  8, 18, 23, 26, 28, 28, 15, 19,  4, 11, 12, 28, 29, 26,\n",
            "        11, 19, 27,  1,  3,  0,  6,  1, 18,  3, 13, 14, 23, 17,  6, 11,  4, 29,\n",
            "        15, 27, 21, 21, 22,  3, 17,  0, 28, 22, 23, 12, 10, 18,  8, 24, 22, 18,\n",
            "        24,  8,  4,  0,  1,  9,  2, 11, 13,  2,  3, 15, 24, 16,  3,  1, 16,  4,\n",
            "        16,  8, 17, 25,  3, 24, 16,  8,  7,  9, 11,  5, 28, 23, 22,  8, 25,  6,\n",
            "        15,  5, 13, 10, 26, 24, 12, 26, 15, 22, 20, 21,  6,  9,  5, 25, 20,  0,\n",
            "        25, 27, 19, 20,  7, 21,  8,  1, 17, 21,  2, 17, 21, 13, 18,  2, 16, 20,\n",
            "         3,  9,  3, 26, 26, 11, 27, 19, 11, 19, 27, 25, 14, 22, 24, 28, 26,  9,\n",
            "         2,  8, 29, 16,  6, 18])\n",
            "test accuracy: 0.776667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gh2TLKZAFdej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}